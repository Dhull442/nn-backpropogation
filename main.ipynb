{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import random\n",
    "# import csv\n",
    "import math\n",
    "TRAIN_FILE=\"mnist_train.csv\"\n",
    "TEST_FILE=\"mnist_test.csv\"\n",
    "num_layers=2\n",
    "num_itr=10\n",
    "neuron_num=784;\n",
    "result_class=10;\n",
    "step = 0.5;\n",
    "bias=0;\n",
    "model_file=\"model.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.genfromtxt((TRAIN_FILE), delimiter=',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`The biases are always 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filldefault(file,layers):\n",
    "    with open(file,'w') as f:\n",
    "        for layernum in range(0,layers):\n",
    "            if( layernum < layers -1 ):\n",
    "                # fill initial defaults\n",
    "                for i in range(0,neuron_num*neuron_num-1):\n",
    "                    f.write(str(random.uniform(0,1))+\",\");\n",
    "                f.write(str(random.uniform(0,1))+\"\\n\");\n",
    "            else:\n",
    "                # fill initial defaults\n",
    "                for i in range(0,neuron_num*result_class):\n",
    "                    f.write(str(random.uniform(0,1))+\",\");\n",
    "                for i in range((neuron_num)*result_class,neuron_num*(neuron_num) -1):\n",
    "                    f.write(\"0,\")\n",
    "                f.write(\"0\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are from first class to next one. first val ~= input1 -> hidden(1,1) . second val ~= input2 -> hidden(1,1)\n",
    "Biases come after all the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(value):  #implement sigmoid for better results\n",
    "    return 1/(1+math.exp(-(1e-3)*value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(value):\n",
    "    return (1-value)*value*(1e-3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def front_prop(inputs,model,layers):\n",
    "    input_vals = inputs\n",
    "    output_vals = np.array([input_vals])\n",
    "    for layer in range(0,layers):\n",
    "#         print(layer)\n",
    "        input_n = len(input_vals)  # number of inputs of this layer\n",
    "        if(layer == layers - 1):\n",
    "            output_n = result_class;\n",
    "        else:\n",
    "            output_n = neuron_num;  # number of outputs of this layer\n",
    "        outputs = np.zeros(output_n) # outputs of this particular layer\n",
    "        for i in range(0,output_n):\n",
    "            start = i*input_n;\n",
    "            end = (i+1)*input_n;\n",
    "            weights = model[layer,start:end];\n",
    "            net = np.sum(np.multiply(input_vals,weights)) + bias;\n",
    "            outputs[i] = activation_function(net);\n",
    "        if(layer < layers -1):\n",
    "            output_vals = np.vstack([output_vals,np.array([outputs])]);\n",
    "        input_vals = outputs;\n",
    "    return (output_vals,outputs); # giving it as tup as final output will have less size and will cause problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(outputs,targets,model):\n",
    "    layers = len(model);\n",
    "    deltas =np.empty([layers,len(model[0])]); # make a copy for structure\n",
    "    final_out = outputs[1]\n",
    "#     print(final_out)\n",
    "    prev_layer = np.subtract(final_out,targets)\n",
    "#     print(prev_layer)\n",
    "    hidden_out = outputs[0]\n",
    "    for i in range(0,layers):\n",
    "        newprev = np.zeros(neuron_num)\n",
    "        prev_out=hidden_out[-(i+1),:]; # outputs of layer prev to this \n",
    "        if ( i == 0 ):\n",
    "            this_out=final_out\n",
    "            for j in range(0,result_class):\n",
    "                for k in range(0,neuron_num):\n",
    "                    p = prev_layer[j]*derivative(this_out[j])*prev_out[k];\n",
    "                    deltas[-(i+1),k+neuron_num*j] = p;\n",
    "                    newprev[k]+=prev_layer[j]*derivative(this_out[j])*model[-(i+1),k+neuron_num*j];\n",
    "            prev_layer = newprev;\n",
    "        else:\n",
    "            this_out = hidden_out[-i,:];\n",
    "            for j in range(0,neuron_num):\n",
    "                for k in range(0,neuron_num): # wt for k -> j\n",
    "                    p = prev_layer[j]*derivative(this_out[j])*prev_out[k];\n",
    "                    deltas[-(i+1),k+neuron_num*j] = p;\n",
    "                    newprev[k]+=prev_layer[j]*derivative(this_out[j])*model[-(i+1),k+neuron_num*j];\n",
    "            prev_layer = newprev;\n",
    "    return deltas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(outputs,targets,model):\n",
    "    deltas = delta(outputs,targets,model);\n",
    "#     print(np.sum(np.subtract(model,deltas)))\n",
    "    return np.subtract(model,step*deltas);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_back(file,value):\n",
    "    with open(file,'w') as f:\n",
    "        for i in range(0,len(value)):\n",
    "            for j in range(0,len(value[i]) - 1):\n",
    "                f.write(str(value[i,j])+\"\\t\")\n",
    "            f.write(str(value[i,-1])+\"\\n\")\n",
    "        f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output,target):\n",
    "    return 0.5*np.sum(np.power(np.subtract(output,target),2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out(outputs):\n",
    "    return np.where(outputs==outputs.max())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(itr,layer,model_param,file):\n",
    "    while(itr > 0):\n",
    "        print('Iteration '+str(itr))\n",
    "#         a = np.zeros(len(train_data))\n",
    "        for sample in range(0,10):  # for testing only :C\n",
    "            targets = np.zeros(result_class)\n",
    "            targets[train_data[sample,0].astype(int)] = 1;\n",
    "            outputs = front_prop(train_data[sample,1:],model_param,layer)   # outputs is a tuple\n",
    "            net_error = loss_fn(outputs[1],targets)\n",
    "            new_model = back_prop(outputs,targets,model_param)\n",
    "            model_param = new_model\n",
    "#             a[sample] = net_error\n",
    "            print('ITR '+str(itr)+', ERROR FOR SAMPLE NO. '+str(sample)+' : '+str(train_data[sample,0].astype(int))+' ' + str(net_error))\n",
    "        itr = itr -1;\n",
    "#         write_back('trained'+str(itr)+'.csv',model_param)\n",
    "    print('Writing trained model to file!')\n",
    "    write_back('t.csv',model_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model file contains all rows having same number of entries, in last row junk entries are fed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 614656)\n"
     ]
    }
   ],
   "source": [
    "print(model_param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filldefault(\"model.csv\",num_layers);  ## Reset model to initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = np.genfromtxt(model_file,delimiter=\",\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4\n",
      "ITR 4, ERROR FOR SAMPLE NO. 0 : 6 1.6872301198481137\n",
      "ITR 4, ERROR FOR SAMPLE NO. 1 : 1 1.6867227833782943\n",
      "ITR 4, ERROR FOR SAMPLE NO. 2 : 8 1.6855694828959857\n",
      "ITR 4, ERROR FOR SAMPLE NO. 3 : 6 1.6870475566854093\n",
      "ITR 4, ERROR FOR SAMPLE NO. 4 : 8 1.6854393155429266\n",
      "ITR 4, ERROR FOR SAMPLE NO. 5 : 5 1.6819363507949407\n",
      "ITR 4, ERROR FOR SAMPLE NO. 6 : 3 1.684278668562769\n",
      "ITR 4, ERROR FOR SAMPLE NO. 7 : 6 1.6868096557927117\n",
      "ITR 4, ERROR FOR SAMPLE NO. 8 : 1 1.6863905476746288\n",
      "ITR 4, ERROR FOR SAMPLE NO. 9 : 8 1.685141824415225\n",
      "Iteration 3\n",
      "ITR 3, ERROR FOR SAMPLE NO. 0 : 6 1.6866240261662742\n",
      "ITR 3, ERROR FOR SAMPLE NO. 1 : 1 1.6861397212413387\n",
      "ITR 3, ERROR FOR SAMPLE NO. 2 : 8 1.6849636000582695\n",
      "ITR 3, ERROR FOR SAMPLE NO. 3 : 6 1.6864415054091604\n",
      "ITR 3, ERROR FOR SAMPLE NO. 4 : 8 1.684833461526171\n",
      "ITR 3, ERROR FOR SAMPLE NO. 5 : 5 1.6813761303315593\n",
      "ITR 3, ERROR FOR SAMPLE NO. 6 : 3 1.683718220739247\n",
      "ITR 3, ERROR FOR SAMPLE NO. 7 : 6 1.686203664969516\n",
      "ITR 3, ERROR FOR SAMPLE NO. 8 : 1 1.6858075000125805\n",
      "ITR 3, ERROR FOR SAMPLE NO. 9 : 8 1.6845360549595498\n",
      "Iteration 2\n",
      "ITR 2, ERROR FOR SAMPLE NO. 0 : 6 1.6860180821580895\n",
      "ITR 2, ERROR FOR SAMPLE NO. 1 : 1 1.6855568093277449\n",
      "ITR 2, ERROR FOR SAMPLE NO. 2 : 8 1.6843578670947166\n",
      "ITR 2, ERROR FOR SAMPLE NO. 3 : 6 1.685835603865537\n",
      "ITR 2, ERROR FOR SAMPLE NO. 4 : 8 1.6842277574238727\n",
      "ITR 2, ERROR FOR SAMPLE NO. 5 : 5 1.6808160636765317\n",
      "ITR 2, ERROR FOR SAMPLE NO. 6 : 3 1.6831579261411533\n",
      "ITR 2, ERROR FOR SAMPLE NO. 7 : 6 1.685597823952973\n",
      "ITR 2, ERROR FOR SAMPLE NO. 8 : 1 1.6852246027201645\n",
      "ITR 2, ERROR FOR SAMPLE NO. 9 : 8 1.683930435508648\n",
      "Iteration 1\n",
      "ITR 1, ERROR FOR SAMPLE NO. 0 : 6 1.685412288014534\n",
      "ITR 1, ERROR FOR SAMPLE NO. 1 : 1 1.6849740478188073\n",
      "ITR 1, ERROR FOR SAMPLE NO. 2 : 8 1.6837522841961152\n",
      "ITR 1, ERROR FOR SAMPLE NO. 3 : 6 1.6852298522454405\n",
      "ITR 1, ERROR FOR SAMPLE NO. 4 : 8 1.6836222034267703\n",
      "ITR 1, ERROR FOR SAMPLE NO. 5 : 5 1.6802561509960874\n",
      "ITR 1, ERROR FOR SAMPLE NO. 6 : 3 1.6825977849350615\n",
      "ITR 1, ERROR FOR SAMPLE NO. 7 : 6 1.6849921329338868\n",
      "ITR 1, ERROR FOR SAMPLE NO. 8 : 1 1.684641855978571\n",
      "ITR 1, ERROR FOR SAMPLE NO. 9 : 8 1.6833249662531298\n",
      "Writing trained model to file!\n"
     ]
    }
   ],
   "source": [
    "train(4,2,model_param,model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tests,layer,model,outFile):\n",
    "    with open(outFile,'w')  as f:\n",
    "        for i in range(0,len(tests)):\n",
    "            result = out(front_prop(tests[i,:],model,layer)[1])\n",
    "            f.write(str(i+1)+\",\"+str(result)+\"\\n\");\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = np.genfromtxt(TEST_FILE,delimiter=\",\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=np.genfromtxt(model_file,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-293-f62dccfe2cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'submit.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-290-001840293777>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(tests, layer, model, outFile)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfront_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-283-adedd1470faa>\u001b[0m in \u001b[0;36mfront_prop\u001b[0;34m(inputs, model, layers)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_n\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 1930\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   1931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test(test_file,2,model,'submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-07"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
