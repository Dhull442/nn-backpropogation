{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import csv\n",
    "import math\n",
    "TRAIN_FILE=\"mnist_train.csv\"\n",
    "TEST_FILE=\"mnist_test.csv\"\n",
    "num_layers=2\n",
    "num_itr=10\n",
    "neuron_num=784;\n",
    "result_class=10;\n",
    "step = 0.5;\n",
    "bias=0;\n",
    "model_file=\"model.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.genfromtxt((TRAIN_FILE), delimiter=',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`The biases are always 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filldefault(file,layers):\n",
    "    with open(file,'w') as f:\n",
    "        for layernum in range(0,layers):\n",
    "            if( layernum < layers -1 ):\n",
    "                # fill initial defaults\n",
    "                for i in range(0,neuron_num*neuron_num-1):\n",
    "                    f.write(\"0.4,\");\n",
    "                f.write(\"0.5\\n\");\n",
    "            else:\n",
    "                # fill initial defaults\n",
    "                for i in range(0,neuron_num*result_class):\n",
    "                    f.write(\"0.5,\");\n",
    "                for i in range((neuron_num)*result_class,neuron_num*(neuron_num) -1):\n",
    "                    f.write(\"0,\")\n",
    "                f.write(\"0\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are from first class to next one. first val ~= input1 -> hidden(1,1) . second val ~= input2 -> hidden(1,1)\n",
    "Biases come after all the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(value):  #implement sigmoid for better results\n",
    "    return 1/(1+math.exp(-value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(value):\n",
    "    return (1-value)*value;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def front_prop(inputs,model,layers):\n",
    "    input_vals = inputs\n",
    "    output_vals = np.array([input_vals])\n",
    "    for layer in range(0,layers):\n",
    "#         print(layer)\n",
    "        input_n = len(input_vals)  # number of inputs of this layer\n",
    "        if(layer == layers - 1):\n",
    "            output_n = result_class;\n",
    "        else:\n",
    "            output_n = neuron_num;  # number of outputs of this layer\n",
    "        outputs = np.zeros(output_n) # outputs of this particular layer\n",
    "        for i in range(0,output_n):\n",
    "            start = i*input_n;\n",
    "            end = (i+1)*input_n;\n",
    "            weights = model[layer,start:end];\n",
    "            net = np.sum(np.multiply(input_vals,weights)) + bias;\n",
    "            outputs[i] = activation_function(net);\n",
    "        if(layer < layers -1):\n",
    "            output_vals = np.vstack([output_vals,np.array([outputs])]);\n",
    "        input_vals = outputs;\n",
    "    return (output_vals,outputs); # giving it as tup as final output will have less size and will cause problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(outputs,targets,model):\n",
    "    layers = len(model);\n",
    "    deltas = model; # make a copy for structure\n",
    "    final_out = outputs[1]\n",
    "    prev_layer = np.subtract(final_out,targets)\n",
    "    print(prev_layer)\n",
    "    hidden_out = outputs[0]\n",
    "    for i in range(0,layers):\n",
    "        newprev = np.zeros(neuron_num)\n",
    "        prev_out=hidden_out[-(i+1),:]; # outputs of layer prev to this \n",
    "        if ( i == 0 ):\n",
    "            this_out=final_out\n",
    "            for j in range(0,result_class):\n",
    "                for k in range(0,neuron_num):\n",
    "                    p = prev_layer[j]*derivative(this_out[j])*prev_out[k];\n",
    "                    deltas[layers -(i+1),k+neuron_num*j] = p;\n",
    "                    newprev[k]+=prev_layer[j]*derivative(this_out[j])*model[-1,k+neuron_num*j];\n",
    "            prev_layer = newprev;\n",
    "        else:\n",
    "            this_out = hidden_out[-i,:];\n",
    "            for j in range(0,neuron_num):\n",
    "                for k in range(0,neuron_num): # wt for k -> j\n",
    "                    p = prev_layer[j]*derivative(this_out[j])*prev_out[k];\n",
    "                    deltas[-(i+1),k+neuron_num*j] = p;\n",
    "                    newprev[k]+=prev_layer[j]*derivative(this_out[j])*model[-(i+1),k+neuron_num*j];\n",
    "            prev_layer = newprev;\n",
    "    return deltas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(outputs,targets,model):\n",
    "    deltas = delta(outputs,targets,model);\n",
    "    print(np.sum(np.subtract(model,deltas)))\n",
    "    return np.subtract(model,step*deltas);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_back(file,value):\n",
    "    with open(file,'w') as f:\n",
    "        for i in range(0,len(value)):\n",
    "            for j in range(0,len(value[i]) - 1):\n",
    "                f.write(str(value[i,j])+\",\")\n",
    "            f.write(str(value[i,-1])+\"\\n\")\n",
    "        f.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output,target):\n",
    "    return 0.5*np.sum(np.power(np.subtract(output,target),2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out(outputs):\n",
    "    return np.where(outputs==outputs.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(itr,layer,model_param,file):\n",
    "    while(itr > 0):\n",
    "        print('Iteration '+str(itr))\n",
    "        for sample in range(0,1):  # for testing only :C\n",
    "            targets = np.zeros(result_class)\n",
    "            targets[train_data[sample,0].astype(int)] = 1;\n",
    "            outputs = front_prop(train_data[sample,1:],model_param,layer)   # outputs is a tuple\n",
    "            net_error = loss_fn(outputs[1],targets)\n",
    "            new_model = back_prop(outputs,targets,model_param)\n",
    "            model_param = new_model\n",
    "            print('ITR '+str(itr)+', ERROR FOR SAMPLE NO. '+str(sample)+' : ' + str(net_error))\n",
    "        itr = itr -1;\n",
    "    print('Writing trained model to file!')\n",
    "    write_back(file,model_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model file contains all rows having same number of entries, in last row junk entries are fed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249782.49999999968\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(model_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "filldefault(\"model.csv\",num_layers);  ## Reset model to initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = np.genfromtxt(model_file,delimiter=\",\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "0.0\n",
      "ITR 10, ERROR FOR SAMPLE NO. 0 : 4.5\n",
      "Iteration 9\n",
      "[ 0.5  0.5  0.5  0.5  0.5  0.5 -0.5  0.5  0.5  0.5]\n",
      "0.0\n",
      "ITR 9, ERROR FOR SAMPLE NO. 0 : 1.25\n",
      "Iteration 8\n",
      "[ 1.  1.  1.  1.  1.  1. -1.  1.  1.  1.]\n",
      "0.0\n",
      "ITR 8, ERROR FOR SAMPLE NO. 0 : 4.999999999771028\n",
      "Iteration 7\n",
      "[ 0.5  0.5  0.5  0.5  0.5  0.5 -0.5  0.5  0.5  0.5]\n",
      "0.0\n",
      "ITR 7, ERROR FOR SAMPLE NO. 0 : 1.2500000056098264\n",
      "Iteration 6\n",
      "[ 1.  1.  1.  1.  1.  1. -1.  1.  1.  1.]\n",
      "0.0\n",
      "ITR 6, ERROR FOR SAMPLE NO. 0 : 4.999999999771028\n",
      "Iteration 5\n",
      "[ 0.5  0.5  0.5  0.5  0.5  0.5 -0.5  0.5  0.5  0.5]\n",
      "0.0\n",
      "ITR 5, ERROR FOR SAMPLE NO. 0 : 1.2500000056098264\n",
      "Iteration 4\n",
      "[ 1.  1.  1.  1.  1.  1. -1.  1.  1.  1.]\n",
      "0.0\n",
      "ITR 4, ERROR FOR SAMPLE NO. 0 : 4.999999999771028\n",
      "Iteration 3\n",
      "[ 0.5  0.5  0.5  0.5  0.5  0.5 -0.5  0.5  0.5  0.5]\n",
      "0.0\n",
      "ITR 3, ERROR FOR SAMPLE NO. 0 : 1.2500000056098264\n",
      "Iteration 2\n",
      "[ 1.  1.  1.  1.  1.  1. -1.  1.  1.  1.]\n",
      "0.0\n",
      "ITR 2, ERROR FOR SAMPLE NO. 0 : 4.999999999771028\n",
      "Iteration 1\n",
      "[ 0.5  0.5  0.5  0.5  0.5  0.5 -0.5  0.5  0.5  0.5]\n",
      "0.0\n",
      "ITR 1, ERROR FOR SAMPLE NO. 0 : 1.2500000056098264\n",
      "Writing trained model to file!\n"
     ]
    }
   ],
   "source": [
    "train(10,2,model_param,model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tests,layer,model,outFile):\n",
    "    with open(outFile,'w')  as f:\n",
    "        for i in range(0,len(tests)):\n",
    "            result = out(front_prop(tests[i,:],model,layer)[1])\n",
    "            f.write(str(i+1)+\",\"+str(result)+\"\\n\");\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = np.genfromtxt(TEST_FILE,delimiter=\",\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=np.genfromtxt(model_file,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-293-f62dccfe2cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'submit.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-290-001840293777>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(tests, layer, model, outFile)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfront_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-283-adedd1470faa>\u001b[0m in \u001b[0;36mfront_prop\u001b[0;34m(inputs, model, layers)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_n\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 1930\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   1931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test(test_file,2,model,'submit.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
